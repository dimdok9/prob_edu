{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "konlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVDHyEoMvaqK4WCVa2lG8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimdok9/prob_edu/blob/main/konlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ztWx1X3f-AY"
      },
      "source": [
        "# 카카오톡 대화 토픽모델링\r\n",
        "\r\n",
        "LDA, NMF를 이용하여 그룹대화방에 대해 토픽분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk5xvEEFUmBG"
      },
      "source": [
        "# pip install konlpy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O9TxWAvVEdJ"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from konlpy.tag import Okt\r\n",
        "import re\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn.decomposition import TruncatedSVD\r\n",
        "from sklearn import decomposition\r\n",
        "from sklearn.decomposition import LatentDirichletAllocation\r\n",
        "from konlpy.tag import Twitter"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLowbuieVFRB",
        "outputId": "8575c3d7-dc81-4cb7-eb62-dbda5d124a83"
      },
      "source": [
        "\r\n",
        "# Mount drive to access file\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjqXrvTugDhb"
      },
      "source": [
        "# 대화 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDsdouRjVXK_"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/KakaoTalk_DSC.txt', 'r', encoding = 'UTF-8')\r\n",
        "first = True\r\n",
        "\r\n",
        "k = []\r\n",
        "while True:\r\n",
        "    \r\n",
        "    if first == True:\r\n",
        "        first = False\r\n",
        "        f.readline()\r\n",
        "    \r\n",
        "    if not f.readline():\r\n",
        "        break\r\n",
        "            \r\n",
        "    line = f.readline()\r\n",
        "    \r\n",
        "    if not re.match('---', line) and line != '\\n':\r\n",
        "        k.append(line.split(']'))\r\n",
        "        try:\r\n",
        "            k[-1][0] = k[-1][0].replace('[','')\r\n",
        "            k[-1][1] = k[-1][1].replace('[','')\r\n",
        "            k[-1][2] = k[-1][2].replace('\\n','')\r\n",
        "        except:\r\n",
        "            pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "zSb_fsxhVrge",
        "outputId": "0cfa6eb7-487b-4ec6-db3e-3ff2849621c9"
      },
      "source": [
        "df = pd.DataFrame(k)\r\n",
        "df.drop(3,axis = 1, inplace = True)\r\n",
        "df.columns = ['작성자','시각','내용']\r\n",
        "df.tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>작성자</th>\n",
              "      <th>시각</th>\n",
              "      <th>내용</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8045</th>\n",
              "      <td>마사루</td>\n",
              "      <td>오후 5:53</td>\n",
              "      <td>책 제목은 신성모독수준이너</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8046</th>\n",
              "      <td>DK</td>\n",
              "      <td>오전 9:48</td>\n",
              "      <td>https://m.bobaedream.co.kr/board/bbs_view/str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047</th>\n",
              "      <td>DK</td>\n",
              "      <td>오후 12:50</td>\n",
              "      <td>https://youtu.be/8WYHDfJDPDc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8048</th>\n",
              "      <td>DK</td>\n",
              "      <td>오후 9:26</td>\n",
              "      <td>사진</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8049</th>\n",
              "      <td>Jinyoung</td>\n",
              "      <td>오전 11:03</td>\n",
              "      <td>유진 초이까...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           작성자         시각                                                 내용\n",
              "8045       마사루    오후 5:53                                     책 제목은 신성모독수준이너\n",
              "8046        DK    오전 9:48   https://m.bobaedream.co.kr/board/bbs_view/str...\n",
              "8047        DK   오후 12:50                       https://youtu.be/8WYHDfJDPDc\n",
              "8048        DK    오후 9:26                                                 사진\n",
              "8049  Jinyoung   오전 11:03                                          유진 초이까..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWT2hmngVs2T"
      },
      "source": [
        "okt_tag = Okt()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKTXYOhxXEM0"
      },
      "source": [
        "df.dropna(inplace = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLacg7E0cCwl",
        "outputId": "c08fc7e3-23e9-4d47-8c6f-f70d1bec9914"
      },
      "source": [
        "f = open('/content/drive/My Drive/Colab Notebooks/kor_stopwords.txt', 'r', encoding = 'UTF-8')\r\n",
        "lines = f.readlines()\r\n",
        "kor_stopwords = []\r\n",
        "for line in lines:\r\n",
        "  kor_stopwords.append(line[:-1])\r\n",
        "f.close()\r\n",
        "kor_stopwords += ['.', '은', '개', 'ㅋㅋㅋㅋ', '2', '흠', 'ka', '한','...',  '걍','?', '근데', '서', '형', '하는','넘','머', '다', '하고','뭐', '내','는', '???', 'ㅡ','함', '만','안', '라거','도', '고','..','거', 'ㄹㅇ', '.....']\r\n",
        "kor_stopwords += ['....', '아니거', '나도', '라고','인가','이여','ㅋㅋㅋ','거기','인','못','해서','한테','중','노','놈','??','데','그런거','햐','리']\r\n",
        "kor_stopwords += ['님', '니', '글', '10', '면','타','하면','인데','햇','지','누','더','이나','이제','이라','그런','시', '말',]\r\n",
        "kor_stopwords += [':', '!', '소','라', '-','임','있','게','!!!','하는데','이랑','기','랑']\r\n",
        "kor_stopwords[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아', '휴', '아이구', '아이쿠', '아이고', '어', '나', '우리', '저희', '따라']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf9IzHf5VuRL",
        "outputId": "3d6355d4-b30d-4e01-c902-d6aeba74f215"
      },
      "source": [
        "from konlpy.tag import Twitter\r\n",
        "t = Twitter()\r\n",
        "\r\n",
        "def okt_tokenizer(text):\r\n",
        "  # token = okt_tag.morphs(text)\r\n",
        "  token = t.morphs(text)\r\n",
        "  l = []\r\n",
        "  for i in token:\r\n",
        "    if i not in kor_stopwords:\r\n",
        "      l.append(i)\r\n",
        "\r\n",
        "  return l\r\n",
        "\r\n",
        "\r\n",
        "okt_tokenizer('아 정말 재밌다')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['정말', '재밌다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXlMDLsMVzz0"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(\r\n",
        "                                   tokenizer = okt_tokenizer,\r\n",
        "                                   ngram_range = (1,1), \r\n",
        "                                   min_df=2, \r\n",
        "                                   max_df=0.95,  \r\n",
        "                                   max_features = 10000,\r\n",
        "                                  )\r\n",
        "\r\n",
        "tfidf_documents = tfidf_vectorizer.fit_transform(df['내용'])\r\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzImfHScgc4G"
      },
      "source": [
        "# LDA 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLuHSiyVW2my"
      },
      "source": [
        "n_topics = 15\r\n",
        "\r\n",
        "lda = LatentDirichletAllocation(n_components = n_topics, random_state=0)\r\n",
        "lda.fit(tfidf_documents)\r\n",
        "topic_models = lda.components_"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkuo7mPKYzqe",
        "outputId": "62b79e58-2ff9-4d08-f21e-80bf77cd02f5"
      },
      "source": [
        "num_top_words = 10\r\n",
        "\r\n",
        "def display_topics(model, feature_names, no_top_words):\r\n",
        "    for topic_idx, topic in enumerate(model.components_):\r\n",
        "        term_list = [feature_names[i]\r\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\r\n",
        "        print(\"topic %d:\" % (topic_idx), term_list)\r\n",
        "\r\n",
        "\r\n",
        "display_topics(lda, tfidf_feature_names, num_top_words)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic 0: ['오이오이', '소리', '-_-;;', '가고', '싶', '진', '레알', 'ㅋ', '집', '살']\n",
            "topic 1: ['씨벌', '후', '집', '아오', '.........', '대충', '이미', '솔직히', '했는데', '5252']\n",
            "topic 2: ['52', '문제', '센', '가서', '조', '역시', '문', '대', '탁', '돈']\n",
            "topic 3: ['좆', '로나', '그거', '쟞', '한국', '...........', '요새', '존나', '계사', '전']\n",
            "topic 4: ['검색', '샵', '아직', '카이', '세', '스벌', '그것', 'ㅇㅅㅇ', '존나', '하기']\n",
            "topic 5: ['까', '적', '맛', '같은', '상', '없', '난', '이다', '탈출', '수']\n",
            "topic 6: ['씨발', 'ㅜ', '해', '새끼', '비', '음', '후', '어제', '와타시', '왔']\n",
            "topic 7: ['사진', 'soda', '캬', '잘', '껄껄', 'ㅇㅋ', '하루', '케이', '죠', '예수님']\n",
            "topic 8: ['오이', '했', '루', 'ㄱㄱ', '미국', '마사', '라멘', 'ㄴㄴ', '다시', '보다']\n",
            "topic 9: ['같', '이모티콘', '짱', '엔', '전세', '…', '대너', '먹고', '연결', '조']\n",
            "topic 10: ['지금', '오늘', '저녁', '똥', '너무', '진짜', '굿', '하노', '있다거', '가슴']\n",
            "topic 11: ['시벌', '존나', 'da', '그냥', '처럼', '졸라', '와타시', '저런', '겠', '많이']\n",
            "topic 12: ['그게', '키', '동영상', '댕기', '있으면', '이딴', '새', '좆', '사실', '하제']\n",
            "topic 13: ['죠지', '오우', '죠', '........', 'socar', '바이', '씨', '닝겐', '상무', '뜨']\n",
            "topic 14: ['와타시', '료헤', '아아', '차', '회사', '갑자기', '크', '버렸', '장', '군']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu_rl4M8inJl"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qud8Un80gfdN"
      },
      "source": [
        "# NMF 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsdhUJ0fc-gH"
      },
      "source": [
        "X = tfidf_documents\r\n",
        "nmf = decomposition.NMF(n_components=n_topics, random_state=0, init=\"nndsvd\")\r\n",
        "# W = nmf.fit_transform(X) \r\n",
        "# H = nmf.components_\r\n",
        "\r\n",
        "# top = 8\r\n",
        "# topic_index_max = n_topics\r\n",
        "\r\n",
        "# for topic_index in range(0, topic_index_max):\r\n",
        "#     top_indices = np.argsort(H[topic_index, :])[::-1]\r\n",
        "#     top_terms = []\r\n",
        "#     for term_index in top_indices[0:top]:\r\n",
        "#         top_terms.append(tfidf_feature_names[term_index])\r\n",
        "#     print(\"topic \", topic_index, top_terms)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeIaR-O7g4lF"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}